# Neural Network Implementations

This repository contains Python implementations of basic neural networks using NumPy. It includes implementations of neural networks with both sigmoid and softmax activation functions.

## Description

The implemented neural network classes include:

- `SigmoidNeuralNetwork`: A neural network with sigmoid activation function in the output layer.
- `SoftmaxNeuralNetwork`: A neural network with softmax activation function in the output layer.


## Features

- **Activation Functions**: Sigmoid and softmax activation functions.
- **Loss Functions**: Cross-entropy loss functions.
- **Dataset**: Training and testing on the Iris dataset.
- **Visualization**: Plotting of loss curves.

## Usage

1. **Clone the repository**:
```
git clone https://github.com/devprashad/neural-network-using-numpy.git
```
2. **Navigate to the directory**:
```
cd neural-network-using-numpy
```
3. **Run the Python script**:
```
neural_srach.ipynb
```
4. **View the output**:
- Check the plotted loss curves.
- Review the test accuracies printed in the console.

## Requirements

- Python 3.x
- NumPy
- Matplotlib
- scikit-learn

## Credits

- The Iris dataset is obtained from the `sklearn.datasets` module.
